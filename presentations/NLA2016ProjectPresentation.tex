\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{graphicx, epsfig}
\usepackage{amsmath,mathrsfs,amsfonts,amssymb}
\usepackage{subfig}
\usepackage{floatflt}
\usepackage{epic,ecltree}
\usepackage{mathtext}
\usepackage{fancybox}
\usepackage{fancyhdr}
\usepackage{multirow}
\usepackage{enumerate}
\usepackage{epstopdf}
\usepackage{multicol}
\usetheme{Boadilla}%{Singapore}%{Warsaw}%{Warsaw}%{Darmstadt}
\usecolortheme{beaver}
%\definecolor{beamer@blendedblue}{RGB}{15,120,80}
%----------------------------------------------------------------------------------------------------------
\title[\hbox to 56mm{Matrix Completion  \hfill\insertframenumber\,/\,\inserttotalframenumber}]
{Low-Rank Matrix Completion project}
\author[ROY team]{\\
				{\small \textbf{Authors:} Bochkarev Artem, Isachenko Roman \\
					Zharikov Ilya, Ducrouq Anne-Laure}}
\institute[SkolTech]{Skolkovo Institute of Science and Technology \\
	Numerical Linear Algebra course 
    \vspace{0.3cm}
}
\date{December 16, 2016.}
%--------------------------------------------------------------------------------
\begin{document}
%--------------------------------------------------------------------------------
\begin{frame}
%\thispagestyle{empty}
\titlepage
\end{frame}
%--------------------------------------------------------------------------------

\begin{frame}{Problem Statement}
\begin{block}{Task}	
Given the amount of observed matrix entries to reconstruct low-rank matrix approximation.
\end{block}
\vspace{0.3cm}
\textbf{Applications:}
\begin{itemize}
	\item  recommender systems;
	\item image-processing;
	\item imputation of NAs for genomic data;
	\item rank estimation for SVD.
\end{itemize}
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Problem Statement}
\textbf{Notations:}
\begin{itemize}
	\item $M$~--- $n \times m$ unknown matrix;
	\item $\Omega \in \{1, \dots, n\} \times \{1, \dots, m\}$ indices of observed elements;
	\item 
	$$
	P_{\Omega} (M) = 
	\begin{cases}
	M_{ij}, &\text{if} \, (i, j) \in \Omega;\\
	0, &\text{otherwise}.
	\end{cases}
	$$
\end{itemize}
\begin{block}{Optimization Task}
\begin{align*}
	\mathop{\text{minimize}}\limits_{X \in \mathbb{R}^{n \times m}} \quad & 
	\text{rank} (X) \\
	\text{subject to} \quad & P_{\Omega} (X) = P_{\Omega} (M).
\end{align*}
\end{block}
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Related Works}
	\begin{enumerate}
		\item Candes E. J., Recht B. Exact matrix completion via convex optimization. 2009.
		\item Cai J. F., Candes E. J., Shen Z. A singular value thresholding algorithm for matrix completion. 2010.
		\item Mazumder R., Hastie T., Tibshirani R. Spectral regularization algorithms for learning large incomplete matrices. 2010.
		\item Jain P., Meka R., Dhillon I. S. Guaranteed rank minimization via singular value projection. 2010.
		\item Takacs G. et al. Scalable collaborative filtering approaches for large recommender systems. 2009.
		\item Vandereycken B. Low-rank matrix completion by Riemannian optimization. 2013.
	\end{enumerate}
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Convex Relaxation (Candes E. J., Recht B., 2009)}
\begin{block}{Original Task}
	\begin{align*}
	\mathop{\text{minimize}}\limits_{X \in \mathbb{R}^{n \times m}} \quad & 
	\text{rank} (X) \\
	\text{subject to} \quad & P_{\Omega} (X) = P_{\Omega} (M).
	\end{align*}
\end{block}
\begin{block}{Relaxation}
	\begin{align*}
	\mathop{\text{minimize}}\limits_{X \in \mathbb{R}^{n \times m}} \quad & 
	\| X \|_* \\
	\text{subject to} \quad & P_{\Omega} (X) = P_{\Omega} (M).
	\end{align*}
\end{block}
\textbf{Motivation:}
$$
	\text{rank} (X) = |\{ i: \sigma_i(X) \neq 0\}|; \quad 
	\| X \|_* = \sum_{i=1}^{k} \sigma_i(X).
$$
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{SVP}
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{SVT}
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{SoftImpute (Hastie T., Tibshirani R., 2010)}
	\begin{block}{Original Task}
		\begin{align*}
		\mathop{\text{minimize}}\limits_{X \in \mathbb{R}^{n \times m}} \quad & 
		\text{rank} (X) \\
		\text{subject to} \quad & P_{\Omega} (X) = P_{\Omega} (M).
		\end{align*}
	\end{block}
	\begin{block}{Relaxation}
		\begin{align*}
		\mathop{\text{minimize}}\limits_{X \in \mathbb{R}^{n \times m}} \quad & 
		\| X \|_* \\
		\text{subject to} \quad & \| P_{\Omega} (X) - P_{\Omega} (M) \|_F \leq \delta.
		\end{align*}
	\end{block}
	\textbf{Motivation:}
	
		The method is the same as $SVT$ with $\delta = 0$. When $\delta>0$ the overfitting is less possible. 
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{RISMF}
\end{frame}
%--------------------------------------------------------------------------------
\begin{frame}{Riemannian Optimization}
\end{frame}
%--------------------------------------------------------------------------------

\end{document} 